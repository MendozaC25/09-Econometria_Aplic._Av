{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYdTyGq22iMc"
   },
   "source": [
    "\n",
    "# **Econometría Aplicada Avanzada**\n",
    "\n",
    "## Práctica calificada 1: Diferencias en Diferencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9y1n9U5Mz9E"
   },
   "source": [
    "### **Integrantes**\n",
    "\n",
    "1. Gianfranco Romero (20196091)\n",
    "2. Shaska Guevara (20171597)\n",
    "3. Micaela Gutierrez (20171488)\n",
    "4. Eduardo Ramírez (20162936)\n",
    "5. Fernando Mendoza (20105246)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8-ZWAsrGxDv"
   },
   "source": [
    "### **Librerías**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzIL4-hM2uOE"
   },
   "source": [
    "Instalamos las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "qezVGzx__7IA",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "76e0d4b8-0aa7-41b1-d82a-77179b570ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting csdid\n",
      "  Downloading csdid-0.2.5.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from csdid) (2.2.2)\n",
      "Collecting numpy<=1.24.3 (from csdid)\n",
      "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from csdid) (1.13.1)\n",
      "Requirement already satisfied: patsy in /usr/local/lib/python3.10/dist-packages (from csdid) (1.0.1)\n",
      "Requirement already satisfied: plotnine in /usr/local/lib/python3.10/dist-packages (from csdid) (0.14.3)\n",
      "Collecting twine (from csdid)\n",
      "  Downloading twine-6.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->csdid) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->csdid) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->csdid) (2024.2)\n",
      "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from plotnine->csdid) (3.8.0)\n",
      "Requirement already satisfied: mizani~=0.13.0 in /usr/local/lib/python3.10/dist-packages (from plotnine->csdid) (0.13.0)\n",
      "Requirement already satisfied: statsmodels>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from plotnine->csdid) (0.14.4)\n",
      "Collecting pkginfo>=1.8.1 (from twine->csdid)\n",
      "  Downloading pkginfo-1.12.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting readme-renderer>=35.0 (from twine->csdid)\n",
      "  Downloading readme_renderer-44.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from twine->csdid) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt!=0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from twine->csdid) (1.0.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from twine->csdid) (2.2.3)\n",
      "Requirement already satisfied: keyring>=15.1 in /usr/lib/python3/dist-packages (from twine->csdid) (23.5.0)\n",
      "Collecting rfc3986>=1.4.0 (from twine->csdid)\n",
      "  Downloading rfc3986-2.0.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from twine->csdid) (13.9.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from twine->csdid) (24.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->plotnine->csdid) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->plotnine->csdid) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->plotnine->csdid) (4.55.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->plotnine->csdid) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->plotnine->csdid) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.8.0->plotnine->csdid) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->csdid) (1.16.0)\n",
      "Collecting nh3>=0.2.14 (from readme-renderer>=35.0->twine->csdid)\n",
      "  Downloading nh3-0.2.19-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: docutils>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from readme-renderer>=35.0->twine->csdid) (0.21.2)\n",
      "Requirement already satisfied: Pygments>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from readme-renderer>=35.0->twine->csdid) (2.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->twine->csdid) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->twine->csdid) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->twine->csdid) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->twine->csdid) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->twine->csdid) (4.12.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->twine->csdid) (0.1.2)\n",
      "Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading twine-6.0.1-py3-none-any.whl (39 kB)\n",
      "Downloading pkginfo-1.12.0-py3-none-any.whl (32 kB)\n",
      "Downloading readme_renderer-44.0-py3-none-any.whl (13 kB)\n",
      "Downloading rfc3986-2.0.0-py2.py3-none-any.whl (31 kB)\n",
      "Downloading nh3-0.2.19-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m748.3/748.3 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: csdid\n",
      "  Building wheel for csdid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for csdid: filename=csdid-0.2.5-py3-none-any.whl size=22349 sha256=5ab341b5711fc5226e316c81b19853eb31fc426ef1b4d9e476440c683273c3ea\n",
      "  Stored in directory: /root/.cache/pip/wheels/b7/ed/ce/85e1d7548d898fddfa839d8947d1be93af80b8c62d3e724da3\n",
      "Successfully built csdid\n",
      "Installing collected packages: nh3, rfc3986, readme-renderer, pkginfo, numpy, twine, csdid\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
      "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed csdid-0.2.5 nh3-0.2.19 numpy-1.24.3 pkginfo-1.12.0 readme-renderer-44.0 rfc3986-2.0.0 twine-6.0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "15daf216e37c418aa09d6b9fdccaf609",
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.14.4)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.24.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.13.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (2.2.2)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.16.0)\n",
      "Collecting linearmodels\n",
      "  Downloading linearmodels-6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (1.24.3)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (1.13.1)\n",
      "Requirement already satisfied: statsmodels>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (0.14.4)\n",
      "Collecting mypy-extensions>=0.4 (from linearmodels)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: Cython>=3.0.10 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (3.0.11)\n",
      "Collecting pyhdfe>=0.1 (from linearmodels)\n",
      "  Downloading pyhdfe-0.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting formulaic>=1.0.0 (from linearmodels)\n",
      "  Downloading formulaic-1.0.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting setuptools-scm<9.0.0,>=8.0.0 (from setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels)\n",
      "  Downloading setuptools_scm-8.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting interface-meta>=1.2.0 (from formulaic>=1.0.0->linearmodels)\n",
      "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=1.0.0->linearmodels) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=1.0.0->linearmodels) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->linearmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->linearmodels) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->linearmodels) (2024.2)\n",
      "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from setuptools-scm<9.0.0,>=8.0.0->setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (24.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from setuptools-scm<9.0.0,>=8.0.0->setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (75.1.0)\n",
      "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from setuptools-scm<9.0.0,>=8.0.0->setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (2.2.1)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13.0->linearmodels) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->linearmodels) (1.16.0)\n",
      "Downloading linearmodels-6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading formulaic-1.0.2-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.5/94.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading pyhdfe-0.2.0-py3-none-any.whl (19 kB)\n",
      "Downloading setuptools_scm-8.1.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: setuptools-scm, mypy-extensions, interface-meta, pyhdfe, formulaic, linearmodels\n",
      "Successfully installed formulaic-1.0.2 interface-meta-1.3.0 linearmodels-6.1 mypy-extensions-1.0.0 pyhdfe-0.2.0 setuptools-scm-8.1.0\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Collecting pyfixest\n",
      "  Downloading pyfixest-0.26.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: formulaic>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyfixest) (1.0.2)\n",
      "Collecting great-tables>=0.10.0 (from pyfixest)\n",
      "  Downloading great_tables-0.14.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: jinja2<4,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from pyfixest) (3.1.4)\n",
      "Collecting lets-plot>=4.0.0 (from pyfixest)\n",
      "  Downloading lets_plot-4.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numba>=0.58.0 in /usr/local/lib/python3.10/dist-packages (from pyfixest) (0.60.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from pyfixest) (1.24.3)\n",
      "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pyfixest) (2.2.2)\n",
      "Requirement already satisfied: polars>=0.20.1 in /usr/local/lib/python3.10/dist-packages (from pyfixest) (1.9.0)\n",
      "Requirement already satisfied: scipy>=1.6 in /usr/local/lib/python3.10/dist-packages (from pyfixest) (1.13.1)\n",
      "Requirement already satisfied: seaborn>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from pyfixest) (0.13.2)\n",
      "Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from pyfixest) (0.9.0)\n",
      "Collecting tqdm==4.66.4 (from pyfixest)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=1.0.0->pyfixest) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=1.0.0->pyfixest) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=1.0.0->pyfixest) (1.17.0)\n",
      "Collecting commonmark>=0.9.1 (from great-tables>=0.10.0->pyfixest)\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting htmltools>=0.4.1 (from great-tables>=0.10.0->pyfixest)\n",
      "  Downloading htmltools-0.6.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from great-tables>=0.10.0->pyfixest) (8.5.0)\n",
      "Requirement already satisfied: Babel>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from great-tables>=0.10.0->pyfixest) (2.16.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from great-tables>=0.10.0->pyfixest) (6.4.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4,>=3.1.4->pyfixest) (3.0.2)\n",
      "Collecting pypng (from lets-plot>=4.0.0->pyfixest)\n",
      "  Downloading pypng-0.20220715.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting palettable (from lets-plot>=4.0.0->pyfixest)\n",
      "  Downloading palettable-3.3.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.58.0->pyfixest) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->pyfixest) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->pyfixest) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->pyfixest) (2024.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn>=0.13.2->pyfixest) (3.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from htmltools>=0.4.1->great-tables>=0.10.0->pyfixest) (24.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.13.2->pyfixest) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.13.2->pyfixest) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.13.2->pyfixest) (4.55.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.13.2->pyfixest) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.13.2->pyfixest) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.13.2->pyfixest) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.0->pyfixest) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->great-tables>=0.10.0->pyfixest) (3.21.0)\n",
      "Downloading pyfixest-0.26.2-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading great_tables-0.14.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lets_plot-4.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading htmltools-0.6.0-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading palettable-3.3.3-py2.py3-none-any.whl (332 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.3/332.3 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypng-0.20220715.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypng, commonmark, tqdm, palettable, htmltools, lets-plot, great-tables, pyfixest\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.6\n",
      "    Uninstalling tqdm-4.66.6:\n",
      "      Successfully uninstalled tqdm-4.66.6\n",
      "Successfully installed commonmark-0.9.1 great-tables-0.14.0 htmltools-0.6.0 lets-plot-4.5.1 palettable-3.3.3 pyfixest-0.26.2 pypng-0.20220715.0 tqdm-4.66.4\n",
      "Collecting drdid\n",
      "  Downloading drdid-1.1.5.tar.gz (5.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from drdid) (2.2.2)\n",
      "Requirement already satisfied: numpy<=1.24.3 in /usr/local/lib/python3.10/dist-packages (from drdid) (1.24.3)\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from drdid) (0.14.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->drdid) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->drdid) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->drdid) (2024.2)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.10/dist-packages (from statsmodels->drdid) (1.13.1)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->drdid) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->drdid) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->drdid) (1.16.0)\n",
      "Building wheels for collected packages: drdid\n",
      "  Building wheel for drdid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for drdid: filename=drdid-1.1.5-py3-none-any.whl size=7268 sha256=f68687afd6e95d373631eddf0f4b93b9c4621e119333319a8310307f3dc2aa0f\n",
      "  Stored in directory: /root/.cache/pip/wheels/c1/a7/bc/dbdf346654ecd87220a60f4ae236e56f5f46614f81e987b7f7\n",
      "Successfully built drdid\n",
      "Installing collected packages: drdid\n",
      "Successfully installed drdid-1.1.5\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
      "Collecting pyreadstat\n",
      "  Downloading pyreadstat-1.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyreadstat) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.16.0)\n",
      "Downloading pyreadstat-1.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyreadstat\n",
      "Successfully installed pyreadstat-1.2.8\n"
     ]
    }
   ],
   "source": [
    "!pip install csdid\n",
    "!pip install pandas\n",
    "!pip install statsmodels\n",
    "!pip install linearmodels\n",
    "!pip install matplotlib\n",
    "!pip install pyfixest\n",
    "!pip install drdid\n",
    "!pip install requests\n",
    "!pip install pyreadstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfHfqgznMe56"
   },
   "source": [
    "Y luego las importamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qCPtuyqj27uT"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"tY6Z61\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.5.1/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"tY6Z61\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"tY6Z61\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"NX5VG1\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.5.1/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"NX5VG1\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"NX5VG1\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from csdid.att_gt import ATTgt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from linearmodels.panel import PanelOLS\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.formula.api import ols\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import csdid\n",
    "import pyfixest as pf\n",
    "import requests\n",
    "import pyreadstat\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "from scipy import stats\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
    "from statsmodels.sandbox.regression.gmm import IVGMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8I9qFUz3rrr"
   },
   "source": [
    "Cargamos la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP40hf_ScXAN",
    "outputId": "e40bd091-9661-4511-afbd-95b888bfbcaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  nearc2  nearc4  educ  age  fatheduc  motheduc    weight  momdad14  \\\n",
      "0   2       0       0     7   29       NaN       NaN  158413.0         1   \n",
      "1   3       0       0    12   27       8.0       8.0  380166.0         1   \n",
      "2   4       0       0    12   34      14.0      12.0  367470.0         1   \n",
      "3   5       1       1    11   27      11.0      12.0  380166.0         1   \n",
      "4   6       1       1    12   34       8.0       7.0  367470.0         1   \n",
      "\n",
      "   sinmom14  ...  smsa66  wage  enroll   KWW     IQ  married  libcrd14  exper  \\\n",
      "0         0  ...       1   548       0  15.0    NaN      1.0       0.0     16   \n",
      "1         0  ...       1   481       0  35.0   93.0      1.0       1.0      9   \n",
      "2         0  ...       1   721       0  42.0  103.0      1.0       1.0     16   \n",
      "3         0  ...       1   250       0  25.0   88.0      1.0       1.0     10   \n",
      "4         0  ...       1   729       0  34.0  108.0      1.0       0.0     16   \n",
      "\n",
      "      lwage  expersq  \n",
      "0  6.306275      256  \n",
      "1  6.175867       81  \n",
      "2  6.580639      256  \n",
      "3  5.521461      100  \n",
      "4  6.591674      256  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# Creamos un enlace directo al archivo usando el servicio raw de GitHub\n",
    "url = \"https://github.com/micaelagn/Micaela-G/raw/refs/heads/main/PC2/card.dta\"\n",
    "\n",
    "# Cargamos el archivo .dta\n",
    "data = pd.read_stata(url)\n",
    "\n",
    "# Y verificamos que se cargó correctamente mostrando las primeras filas\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjKfEzD3kKGI"
   },
   "source": [
    "### 1. Realice una descripción de las características de los individuos de la muestra. <br> ¿Qué información nos provee el promedio de la dependiente en la interpretación de los coeficientes? <br>¿Cómo se interpretan los coeficientes en este caso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NtA-uW9_odE6",
    "outputId": "b747df07-7826-49e6-c707-b45d730377d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                id       nearc2       nearc4         educ          age  \\\n",
      "count  3010.000000  3010.000000  3010.000000  3010.000000  3010.000000   \n",
      "mean   2581.748837     0.440864     0.682060    13.263455    28.119601   \n",
      "std    1500.538849     0.496573     0.465753     2.676913     3.137004   \n",
      "min       2.000000     0.000000     0.000000     1.000000    24.000000   \n",
      "25%    1275.500000     0.000000     0.000000    12.000000    25.000000   \n",
      "50%    2541.000000     0.000000     1.000000    13.000000    28.000000   \n",
      "75%    3858.750000     1.000000     1.000000    16.000000    31.000000   \n",
      "max    5225.000000     1.000000     1.000000    18.000000    34.000000   \n",
      "\n",
      "          fatheduc     motheduc        weight     momdad14     sinmom14  ...  \\\n",
      "count  2320.000000  2657.000000  3.010000e+03  3010.000000  3010.000000  ...   \n",
      "mean     10.003448    10.348137  3.211852e+05     0.789369     0.100664  ...   \n",
      "std       3.720737     3.179671  1.706459e+05     0.407825     0.300934  ...   \n",
      "min       0.000000     0.000000  7.560700e+04     0.000000     0.000000  ...   \n",
      "25%       8.000000     8.000000  1.227980e+05     1.000000     0.000000  ...   \n",
      "50%      10.000000    12.000000  3.652000e+05     1.000000     0.000000  ...   \n",
      "75%      12.000000    12.000000  4.060240e+05     1.000000     0.000000  ...   \n",
      "max      18.000000    18.000000  1.752340e+06     1.000000     1.000000  ...   \n",
      "\n",
      "            smsa66         wage       enroll          KWW           IQ  \\\n",
      "count  3010.000000  3010.000000  3010.000000  2963.000000  2061.000000   \n",
      "mean      0.649502   577.282392     0.092359    33.540668   102.449782   \n",
      "std       0.477205   262.958302     0.289580     8.611619    15.423756   \n",
      "min       0.000000   100.000000     0.000000     4.000000    50.000000   \n",
      "25%       0.000000   394.250000     0.000000    28.000000    93.000000   \n",
      "50%       1.000000   537.500000     0.000000    34.000000   103.000000   \n",
      "75%       1.000000   708.750000     0.000000    40.000000   113.000000   \n",
      "max       1.000000  2404.000000     1.000000    56.000000   149.000000   \n",
      "\n",
      "           married     libcrd14        exper        lwage      expersq  \n",
      "count  3003.000000  2997.000000  3010.000000  3010.000000  3010.000000  \n",
      "mean      2.271395     0.674341     8.856146     6.261832    95.579070  \n",
      "std       2.066823     0.468699     4.141672     0.443797    84.618314  \n",
      "min       1.000000     0.000000     0.000000     4.605170     0.000000  \n",
      "25%       1.000000     0.000000     6.000000     5.976985    36.000000  \n",
      "50%       1.000000     1.000000     8.000000     6.286928    64.000000  \n",
      "75%       4.000000     1.000000    11.000000     6.563503   121.000000  \n",
      "max       6.000000     1.000000    23.000000     7.784889   529.000000  \n",
      "\n",
      "[8 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# Estadísticas descriptivas generales\n",
    "print(data.describe())  # Para variables numéricas\n",
    "\n",
    "# Distribución de variables categóricas\n",
    "categorical_cols = data.select_dtypes(include='category').columns\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\nDistribución de {col}:\")\n",
    "    print(data[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJ4CylHJusni",
    "outputId": "16c70813-a63d-4ef2-a9c1-1b5c18f7c54f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio de la dependiente (wage): 577.2823920265781\n"
     ]
    }
   ],
   "source": [
    "print(f\"Promedio de la dependiente (wage): {data['wage'].mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmDUmxlzkPxj"
   },
   "source": [
    "### 2. Regresione usando OLS el siguiente modelo en Stata <br> `reg` `lwage` `educ` `c.exper##c.exper` `age` `black` `south` `smsa` , `smsa66`,`reg661-reg668`<br> ¿Qué ocurre con edad? ¿Por qué? <br> Ahora saque edad del modelo anterior y regresione de nuevo. <br> Interprete el estimado obtenido para educación, y compárelos con la `Tabla 2` y `Columna 2` del paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-yk88ZwOoeHS",
    "outputId": "b3d9416a-e27d-4d89-8bdc-06df928cec02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  lwage   R-squared:                       0.209\n",
      "Model:                            OLS   Adj. R-squared:                  0.201\n",
      "Method:                 Least Squares   F-statistic:                     27.87\n",
      "Date:                Sun, 08 Dec 2024   Prob (F-statistic):           4.00e-70\n",
      "Time:                        19:13:50   Log-Likelihood:                -690.90\n",
      "No. Observations:                1600   AIC:                             1414.\n",
      "Df Residuals:                    1584   BIC:                             1500.\n",
      "Df Model:                          15                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.3522      0.009     41.103      0.000       0.335       0.369\n",
      "educ          -0.6699      0.020    -34.269      0.000      -0.708      -0.632\n",
      "exper         -0.6981      0.017    -40.418      0.000      -0.732      -0.664\n",
      "exper_sq       0.0004      0.000      2.124      0.034    2.83e-05       0.001\n",
      "age            0.7451      0.015     50.372      0.000       0.716       0.774\n",
      "black         -0.1592      0.033     -4.850      0.000      -0.224      -0.095\n",
      "south         -0.0946      0.037     -2.570      0.010      -0.167      -0.022\n",
      "smsa           0.1267      0.028      4.588      0.000       0.073       0.181\n",
      "smsa66         0.0367      0.026      1.389      0.165      -0.015       0.088\n",
      "reg661        -0.0972      0.052     -1.857      0.063      -0.200       0.005\n",
      "reg662         0.0066      0.035      0.186      0.853      -0.063       0.076\n",
      "reg663         0.0152      0.035      0.436      0.663      -0.053       0.084\n",
      "reg664        -0.0473      0.045     -1.045      0.296      -0.136       0.042\n",
      "reg665         0.0060      0.049      0.122      0.903      -0.090       0.102\n",
      "reg666         0.0591      0.059      0.994      0.320      -0.057       0.176\n",
      "reg667        -0.0324      0.054     -0.604      0.546      -0.138       0.073\n",
      "reg668        -0.1531      0.058     -2.619      0.009      -0.268      -0.038\n",
      "==============================================================================\n",
      "Omnibus:                       47.641   Durbin-Watson:                   1.906\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               57.487\n",
      "Skew:                          -0.358   Prob(JB):                     3.29e-13\n",
      "Kurtosis:                       3.591   Cond. No.                     1.55e+17\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 3.03e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Crear el término cuadrático de exper\n",
    "data['exper_sq'] = data['exper'] ** 2\n",
    "\n",
    "# Modelo con edad\n",
    "formula_1 = \"lwage ~ educ + exper + exper_sq + age + black + south + smsa + smsa66 + reg661 + reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668\"\n",
    "\n",
    "# Ajustar el modelo\n",
    "model_1 = smf.ols(formula=formula_1, data=data.dropna()).fit()\n",
    "\n",
    "# Resumen del modelo\n",
    "print(model_1.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZJMU43911hs",
    "outputId": "b2246751-00b1-493e-8faa-e9515ead5ded"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  lwage   R-squared:                       0.209\n",
      "Model:                            OLS   Adj. R-squared:                  0.201\n",
      "Method:                 Least Squares   F-statistic:                     27.87\n",
      "Date:                Sun, 08 Dec 2024   Prob (F-statistic):           4.00e-70\n",
      "Time:                        19:13:54   Log-Likelihood:                -690.90\n",
      "No. Observations:                1600   AIC:                             1414.\n",
      "Df Residuals:                    1584   BIC:                             1500.\n",
      "Df Model:                          15                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      4.8229      0.097     49.562      0.000       4.632       5.014\n",
      "educ           0.0752      0.005     14.590      0.000       0.065       0.085\n",
      "exper          0.0470      0.003     14.463      0.000       0.041       0.053\n",
      "exper_sq       0.0004      0.000      2.124      0.034    2.83e-05       0.001\n",
      "black         -0.1592      0.033     -4.850      0.000      -0.224      -0.095\n",
      "south         -0.0946      0.037     -2.570      0.010      -0.167      -0.022\n",
      "smsa           0.1267      0.028      4.588      0.000       0.073       0.181\n",
      "smsa66         0.0367      0.026      1.389      0.165      -0.015       0.088\n",
      "reg661        -0.0972      0.052     -1.857      0.063      -0.200       0.005\n",
      "reg662         0.0066      0.035      0.186      0.853      -0.063       0.076\n",
      "reg663         0.0152      0.035      0.436      0.663      -0.053       0.084\n",
      "reg664        -0.0473      0.045     -1.045      0.296      -0.136       0.042\n",
      "reg665         0.0060      0.049      0.122      0.903      -0.090       0.102\n",
      "reg666         0.0591      0.059      0.994      0.320      -0.057       0.176\n",
      "reg667        -0.0324      0.054     -0.604      0.546      -0.138       0.073\n",
      "reg668        -0.1531      0.058     -2.619      0.009      -0.268      -0.038\n",
      "==============================================================================\n",
      "Omnibus:                       47.641   Durbin-Watson:                   1.906\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               57.487\n",
      "Skew:                          -0.358   Prob(JB):                     3.29e-13\n",
      "Kurtosis:                       3.591   Cond. No.                         774.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Modelo sin edad\n",
    "formula_2 = \"lwage ~ educ + exper + exper_sq + black + south + smsa + smsa66 + reg661 + reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668\"\n",
    "\n",
    "# Ajustar el modelo\n",
    "model_2 = smf.ols(formula=formula_2, data=data.dropna()).fit()\n",
    "\n",
    "# Resumen del modelo\n",
    "print(model_2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fnmi4tkzlzDD"
   },
   "source": [
    "### 3. Vea la `Tabla 2` de Card (1993). ¿Qué se encuentra al inspeccionar el coeficiente estimado de educación? ¿Es creíble este coeficiente? ¿Por qué? <br> ¿Qué 2 posibles fuentes de inconsistencia podrían ocurrir como resultado de la omisión de variables? <br> Use el marco visto en clase (las expresiones que forman parte de $Inconsistencia=γ \\frac{Cov(x,α)}{Var(x)} $) para responder y mencione la dirección esperada del sesgo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygHmc7qqxMPZ"
   },
   "source": [
    "Al inspeccionar el coeficiente esmitado de educación, se puede ver que los diferentes modelos propuestos muestran un efecto relativamente constante del efecto de cada año de educación sobre los ingresos. Así, cada regresión de OLS muestra que la educación incrementa los ingresos de los hombres encuestados entre 0.74 y 0.75.\n",
    "\n",
    "En realidad, este coeficiente no es creíble. Esto debido a que la educación de cada hombre puede estar relacionada con otras variables que no son medidas pero que igualmente tienen un efecto sobre los ingresos. Es decir, no es creíble este coeficiente estimado de educación pues existe un problema de endogeneidad.\n",
    "\n",
    "La omisión de variables puede dar pie a inconsistencia, que implica que el coeficiente estimado en la muestra realmente no nos dice nada sobre la población. Esta inconsistencia se dará si se cumplen dos condiciones: Primero, si existe una variable no observada que esté afectando la variable que se quiere predecir. Segundo, si alguna variable explicativa del modelo (en nuestro caso, educación) está relacionada con esa variable no observada.\n",
    "\n",
    "Así, en nuestro caso, podemos detectar dos posibles fuentes de inconsistencia dadas por la omisión de variables.\n",
    "\n",
    "a) La habilidad de una persona puede estar relacionada tanto con su educación como con sus ingresos. Si una persona acumula más años de estudios, es razonable pensar que esto le dará una mayor habilidad para realizar su trabajo. Además de ello, si una persona tiene más habilidades para el trabajo, entonces podrá ser más productivo y conseguir mayores ingresos. Así, siguiendo $\\gamma $ positivo y $\\theta_{1}$ igualmente positivo, la dirección del sesgo es positiva.\n",
    "\n",
    "b) Las redes de contactos establecidas en los centros de estudios también están relacionadas con la educación y los ingresos. Lógicmanete, el pasar por un centro educativo, sobre todo uno donde los estudiantes de clase alta, abre la posibilidad de generar vínculos con estos estudiantes y a sus redes de contactos, los cuales son muy útiles al momento de conseguir empleos con mayor remuneración. A medida que una persona tienen más años de educación, esta tiene más tiempo para forjar más vínculos de este tipo. Además, al tener más vínculos, se abren mayores oportunidades para conseguir trabajos mejor pagados. Así, siguiendo $\\gamma $ positivo y $\\theta_{1}$ igualmente positivo, la dirección del sesgo es positiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zd0KB_0mlWL"
   },
   "source": [
    "### 4. Estime la ecuación de primera etapa <br> ¿Qué debemos ver en esta regresión? <br> ¿Qué podría decir respecto de la correlación parcial existente entre `educ` y `nearc4`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rIho8-xwxcpo",
    "outputId": "515d1e76-ea1c-4d62-a4ec-3b506a933713"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   educ   R-squared:                       0.021\n",
      "Model:                            OLS   Adj. R-squared:                  0.020\n",
      "Method:                 Least Squares   F-statistic:                     63.91\n",
      "Date:                Sun, 08 Dec 2024   Prob (F-statistic):           1.84e-15\n",
      "Time:                        19:14:01   Log-Likelihood:                -7202.7\n",
      "No. Observations:                3010   AIC:                         1.441e+04\n",
      "Df Residuals:                    3008   BIC:                         1.442e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         12.6980      0.086    148.269      0.000      12.530      12.866\n",
      "nearc4         0.8290      0.104      7.994      0.000       0.626       1.032\n",
      "==============================================================================\n",
      "Omnibus:                       26.936   Durbin-Watson:                   1.626\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               28.373\n",
      "Skew:                          -0.204   Prob(JB):                     6.90e-07\n",
      "Kurtosis:                       3.243   Cond. No.                         3.31\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Ecuación de primera etapa sin controles\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "y_ols = data['educ']\n",
    "X_ols = sm.add_constant(data['nearc4'])\n",
    "model_first_stage = sm.OLS(y_ols, X_ols).fit()\n",
    "print(model_first_stage.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxTixYdJctM2"
   },
   "source": [
    "Podemos ver que existe un coeficiente de 0.82 para nearc4. Existe una correlación positiva muy fuerte entre esta variable y los años de educación. Esto nos sugeriría que se trata de un buen instrumento para aplicar una estrategia de variables instrumentales. A continuación, incluiremos variables de control en el modelo para tener una mejor estimación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EImApT6Jxgyf",
    "outputId": "16707701-0ddd-465d-96c0-3abbd628110e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   educ   R-squared:                       0.133\n",
      "Model:                            OLS   Adj. R-squared:                  0.129\n",
      "Method:                 Least Squares   F-statistic:                     32.88\n",
      "Date:                Sun, 08 Dec 2024   Prob (F-statistic):           9.50e-83\n",
      "Time:                        19:14:04   Log-Likelihood:                -7019.2\n",
      "No. Observations:                3010   AIC:                         1.407e+04\n",
      "Df Residuals:                    2995   BIC:                         1.416e+04\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         12.4998      0.211     59.229      0.000      12.086      12.914\n",
      "nearc4         0.4056      0.113      3.586      0.000       0.184       0.627\n",
      "momdad14       0.7917      0.117      6.767      0.000       0.562       1.021\n",
      "south         -0.1887      0.174     -1.082      0.279      -0.531       0.153\n",
      "black         -1.1783      0.124     -9.494      0.000      -1.422      -0.935\n",
      "smsa           0.9660      0.134      7.217      0.000       0.704       1.228\n",
      "reg661        -0.6015      0.260     -2.310      0.021      -1.112      -0.091\n",
      "reg662        -0.2472      0.190     -1.303      0.193      -0.619       0.125\n",
      "reg663        -0.2349      0.184     -1.279      0.201      -0.595       0.125\n",
      "reg664        -0.0365      0.239     -0.152      0.879      -0.506       0.433\n",
      "reg665        -0.6073      0.242     -2.507      0.012      -1.082      -0.132\n",
      "reg666        -0.5493      0.270     -2.035      0.042      -1.079      -0.020\n",
      "reg667        -0.3875      0.265     -1.464      0.143      -0.907       0.131\n",
      "reg668         0.3690      0.311      1.186      0.236      -0.241       0.979\n",
      "smsa66        -0.2275      0.136     -1.674      0.094      -0.494       0.039\n",
      "==============================================================================\n",
      "Omnibus:                       20.578   Durbin-Watson:                   1.763\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               22.934\n",
      "Skew:                          -0.151   Prob(JB):                     1.05e-05\n",
      "Kurtosis:                       3.302   Cond. No.                         22.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "F test of excluded instruments:\n",
      " F-statistic = 12.86\n",
      " Prob > F = 0.0003\n",
      "Stock-Yogo weak ID test critical values for single endogenous regressor:\n",
      "                                   10% maximal IV size             16.38\n",
      "                                   15% maximal IV size              8.96\n",
      "                                   20% maximal IV size              6.66\n",
      "                                   25% maximal IV size              5.53\n",
      "Source: Stock-Yogo (2005).\n"
     ]
    }
   ],
   "source": [
    "y_ols = data['educ']\n",
    "# Los controles son tomados de la Tabla 2 de Card (1993)\n",
    "X_ols = sm.add_constant(data[['nearc4','momdad14','south','black','smsa','reg661','reg662','reg663','reg664','reg665','reg666','reg667','reg668','smsa66']])\n",
    "model_first_stage = sm.OLS(y_ols, X_ols).fit()\n",
    "print(model_first_stage.summary())\n",
    "\n",
    "\n",
    "coef_nearc4 = model_first_stage.params['nearc4']\n",
    "cov_nearc4 = model_first_stage.cov_params().loc['nearc4', 'nearc4']\n",
    "\n",
    "f_stat = (coef_nearc4 ** 2) / cov_nearc4\n",
    "\n",
    "df_num = 1\n",
    "df_den = model_first_stage.df_resid\n",
    "\n",
    "p_value = 1 - stats.f.cdf(f_stat, df_num, df_den)\n",
    "print(f\"F test of excluded instruments:\\n F-statistic = {f_stat:.2f}\\n Prob > F = {p_value:.4f}\")\n",
    "\n",
    "print(\"Stock-Yogo weak ID test critical values for single endogenous regressor:\")\n",
    "print(\"                                   10% maximal IV size             16.38\")\n",
    "print(\"                                   15% maximal IV size              8.96\")\n",
    "print(\"                                   20% maximal IV size              6.66\")\n",
    "print(\"                                   25% maximal IV size              5.53\")\n",
    "print(\"Source: Stock-Yogo (2005).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fY9eKMVExsT3"
   },
   "source": [
    "Al estimar la regresión con variables de control, podemos ver que el coeficiente de nearc4 se reduce a 0.4056. Es decir, tiene una correlación más débil con respecto a la educación. Es más, podemos ver que otras variables como haber vivido con ambos padres a los 14 años (*momdad14*), ser afroamericano (*black*) o vivir en una zona metropolitana (*smsa*) tienen coeficientes más fuertes que nearc4. Ahora bien, al ver el F-Statistic, vemos que es de 12.86. Al compararlo con los valores críticos de Stock y Yogo, vemos que la estimación de IV puede tener, como máximo, un 15% de sesgo del $\\beta$ original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-5_L_vZnAVD"
   },
   "source": [
    "### 5. Estime el modelo usando el estimador de Variables Instrumentales, usando `nearc4` como un instrumento para la variable educ. <br> Dibuje el DAG correspondiente y explique por qué se espera que esta estrategia funcione. <br> Comente sus resultados y compárelos con los obtenidos en el punto 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observan diferencias importantes en la estimación del coeficiente de la variable educ (educación), lo que refleja el impacto de la endogeneidad en los resultados obtenidos mediante la regresión OLS. En el modelo OLS, el coeficiente estimado para la variable educación es de 19.62, lo que implica que, en promedio, un incremento en el nivel educativo está asociado con un aumento de 19.62 unidades en el salario. Sin embargo, esta estimación puede estar sesgada debido a la presencia de endogeneidad, que se refiere a la correlación entre el regressor (educación) y el error en el modelo. La endogeneidad puede surgir de factores no observados que afectan tanto al salario como a la educación, como habilidades innatas o factores no medidos que determinan tanto el nivel educativo como los ingresos, lo que lleva a una subestimación del verdadero impacto de la educación en el salario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado, el modelo IV, al utilizar el instrumento `nearc4` para corregir esta endogeneidad, proporciona una estimación significativamente mayor para el coeficiente de educación, alcanzando un valor de 61.39. Esto sugiere que, una vez corregido el sesgo de endogeneidad, el verdadero efecto de la educación sobre el salario es mucho mayor de lo que se indicaba en el modelo OLS. Es decir, el uso de un instrumento exógeno permite aislar el efecto causal de la educación sobre el salario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto al R-cuadrado, se observa una marcada discrepancia entre los dos modelos. El modelo OLS tiene un R-cuadrado de 0.184, lo que indica que el 18.4% de la variabilidad en los salarios es explicada por las variables independientes del modelo, lo que podría sugerir un ajuste relativamente bueno, especialmente cuando no se tiene en cuenta la endogeneidad. En contraste, el modelo IV tiene un R-cuadrado de 0.026, lo que refleja una capacidad explicativa mucho menor del modelo. Este es un hallazgo típico en modelos IV, ya que el objetivo principal no es maximizar el ajuste, sino corregir la endogeneidad y obtener estimaciones causales más precisas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, tanto el modelo OLS como el modelo IV muestran que el coeficiente de educación es estadísticamente significativo, con p-valores muy bajos (prueba de hipótesis nula de que el coeficiente es igual a cero). Sin embargo, la confiabilidad de las estimaciones es considerablemente mayor en el modelo IV, dado que ha corregido el sesgo de endogeneidad. En resumen, aunque el modelo OLS puede ofrecer una buena predicción general del salario, el modelo IV proporciona una estimación más robusta y precisa del efecto causal de la educación, ajustada por la endogeneidad, lo que lo convierte en la opción preferida cuando se busca inferir relaciones causales más confiables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "OQzHBcTjog-4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F test de exclusión del instrumento:\n",
      "F-statistic = 12.86\n",
      "Prob > F = 0.0003\n",
      "Stock-Yogo weak ID test critical values para un regresor endógeno:\n",
      "                                   10% tamaño IV máximo             16.38\n",
      "                                   15% tamaño IV máximo              8.96\n",
      "                                   20% tamaño IV máximo              6.66\n",
      "                                   25% tamaño IV máximo              5.53\n",
      "\n",
      "Resultados del estimador IV usando 'nearc4' como instrumento:\n",
      "                          IV2SLS Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   wage   R-squared:                       0.026\n",
      "Model:                         IV2SLS   Adj. R-squared:                  0.022\n",
      "Method:                     Two Stage   F-statistic:                     33.04\n",
      "                        Least Squares   Prob (F-statistic):           3.79e-83\n",
      "Date:                Sun, 08 Dec 2024                                         \n",
      "Time:                        20:02:12                                         \n",
      "No. Observations:                3010                                         \n",
      "Df Residuals:                    2995                                         \n",
      "Df Model:                          14                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       -216.6875    369.023     -0.587      0.557    -940.251     506.876\n",
      "educ          61.3897     29.037      2.114      0.035       4.456     118.324\n",
      "momdad14     -10.2665     25.776     -0.398      0.690     -60.808      40.274\n",
      "south        -66.8317     19.026     -3.513      0.000    -104.137     -29.526\n",
      "black        -51.3076     36.108     -1.421      0.155    -122.107      19.492\n",
      "smsa          21.5238     32.343      0.665      0.506     -41.892      84.940\n",
      "reg661       -49.0203     31.840     -1.540      0.124    -111.450      13.410\n",
      "reg662       -20.1664     20.730     -0.973      0.331     -60.814      20.481\n",
      "reg663         1.2876     20.501      0.063      0.950     -38.910      41.485\n",
      "reg664       -60.4322     24.958     -2.421      0.016    -109.369     -11.495\n",
      "reg665         8.1056     31.362      0.258      0.796     -53.388      69.599\n",
      "reg666        10.5333     33.582      0.314      0.754     -55.313      76.380\n",
      "reg667        -6.7694     30.514     -0.222      0.824     -66.600      53.061\n",
      "reg668      -129.2101     33.723     -3.831      0.000    -195.333     -63.087\n",
      "smsa66        34.3150     13.810      2.485      0.013       7.237      61.393\n",
      "==============================================================================\n",
      "Omnibus:                      448.303   Durbin-Watson:                   1.866\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1182.225\n",
      "Skew:                           0.813   Prob(JB):                    1.92e-257\n",
      "Kurtosis:                       5.605   Cond. No.                         160.\n",
      "==============================================================================\n",
      "\n",
      "Resultados del modelo OLS (de la pregunta 2):\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   wage   R-squared:                       0.184\n",
      "Model:                            OLS   Adj. R-squared:                  0.180\n",
      "Method:                 Least Squares   F-statistic:                     48.12\n",
      "Date:                Sun, 08 Dec 2024   Prob (F-statistic):          6.81e-121\n",
      "Time:                        20:02:12   Log-Likelihood:                -20737.\n",
      "No. Observations:                3010   AIC:                         4.150e+04\n",
      "Df Residuals:                    2995   BIC:                         4.159e+04\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        313.2770     29.431     10.644      0.000     255.569     370.985\n",
      "educ          19.6196      1.738     11.287      0.000      16.211      23.028\n",
      "momdad14      22.4138     11.233      1.995      0.046       0.388      44.440\n",
      "south        -75.0314     16.624     -4.513      0.000    -107.627     -42.436\n",
      "black        -99.8153     11.995     -8.322      0.000    -123.334     -76.296\n",
      "smsa          63.5410     12.837      4.950      0.000      38.371      88.711\n",
      "reg661       -73.0635     24.834     -2.942      0.003    -121.756     -24.371\n",
      "reg662       -29.3004     18.073     -1.621      0.105     -64.737       6.136\n",
      "reg663        -9.3883     17.504     -0.536      0.592     -43.708      24.932\n",
      "reg664       -62.2093     22.824     -2.726      0.006    -106.962     -17.456\n",
      "reg665       -18.7494     23.101     -0.812      0.417     -64.045      26.547\n",
      "reg666       -16.1701     25.648     -0.630      0.528     -66.460      34.120\n",
      "reg667       -25.8357     25.178     -1.026      0.305     -75.204      23.533\n",
      "reg668      -115.5873     29.641     -3.900      0.000    -173.705     -57.469\n",
      "smsa66        30.6155     12.424      2.464      0.014       6.254      54.977\n",
      "==============================================================================\n",
      "Omnibus:                      888.421   Durbin-Watson:                   1.853\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3853.380\n",
      "Skew:                           1.371   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.818   Cond. No.                         160.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
    "from scipy import stats\n",
    "\n",
    "# Primera etapa: Regresión de 'educ' sobre 'nearc4' y controles\n",
    "# Variables dependientes y explicativas\n",
    "y_first_stage = data['educ']\n",
    "X_first_stage = sm.add_constant(data[['nearc4', 'momdad14', 'south', 'black', 'smsa', \n",
    "                                      'reg661', 'reg662', 'reg663', 'reg664', 'reg665', \n",
    "                                      'reg666', 'reg667', 'reg668', 'smsa66']])\n",
    "\n",
    "model_first_stage = sm.OLS(y_first_stage, X_first_stage).fit()\n",
    "\n",
    "# Evaluación de la fuerza del instrumento (F-statistic)\n",
    "coef_nearc4 = model_first_stage.params['nearc4']\n",
    "cov_nearc4 = model_first_stage.cov_params().loc['nearc4', 'nearc4']\n",
    "f_stat = (coef_nearc4 ** 2) / cov_nearc4\n",
    "df_num = 1\n",
    "df_den = model_first_stage.df_resid\n",
    "p_value = 1 - stats.f.cdf(f_stat, df_num, df_den)\n",
    "\n",
    "print(f\"\\nF test de exclusión del instrumento:\\nF-statistic = {f_stat:.2f}\\nProb > F = {p_value:.4f}\")\n",
    "print(\"Stock-Yogo weak ID test critical values para un regresor endógeno:\")\n",
    "print(\"                                   10% tamaño IV máximo             16.38\")\n",
    "print(\"                                   15% tamaño IV máximo              8.96\")\n",
    "print(\"                                   20% tamaño IV máximo              6.66\")\n",
    "print(\"                                   25% tamaño IV máximo              5.53\")\n",
    "\n",
    "# Segunda etapa: Regresión de 'wage' sobre los predictores usando IV\n",
    "y_second_stage = data['wage']  # Variable dependiente\n",
    "X_second_stage = data[['educ', 'momdad14', 'south', 'black', 'smsa', \n",
    "                       'reg661', 'reg662', 'reg663', 'reg664', 'reg665', \n",
    "                       'reg666', 'reg667', 'reg668', 'smsa66']]  # Educ y controles\n",
    "Z = data[['nearc4', 'momdad14', 'south', 'black', 'smsa', \n",
    "          'reg661', 'reg662', 'reg663', 'reg664', 'reg665', \n",
    "          'reg666', 'reg667', 'reg668', 'smsa66']]  # Instrumentos y controles\n",
    "\n",
    "iv_model = IV2SLS(y_second_stage, sm.add_constant(X_second_stage), sm.add_constant(Z)).fit()\n",
    "\n",
    "print(\"\\nResultados del estimador IV usando 'nearc4' como instrumento:\")\n",
    "print(iv_model.summary())\n",
    "\n",
    "# Comparación con OLS (Pregunta 2)\n",
    "ols_model = sm.OLS(y_second_stage, sm.add_constant(X_second_stage)).fit()\n",
    "print(\"\\nResultados del modelo OLS (de la pregunta 2):\")\n",
    "print(ols_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    nearc4\n",
    "       ↓\n",
    "     educ  ← Confusoras (U)\n",
    "       ↓\n",
    "     lwage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9k2iQwX7nN3B"
   },
   "source": [
    "### 6. Testee la presencia de instrumentos débiles usando: <br> **i)** el estadístico F; <br> **ii)** el estadístico de Cragg y Donald (1993); <br> **iii)** las tablas de Stock y Yogo (2005) con respecto a la medida del test de Wald"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) el estadístico F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El estadístico F de la primera etapa es útil para identificar si el instrumento es relevante. Si el valor F es mayor a 10, no hay evidencia de que los instrumentos sean débiles. Dado que Prob > F = 0.0003 es mucho menor que 0.05, esto indica que el instrumento ``nearc4`` es relevante y no es débil. En otras palabras, el instrumento tiene una relación significativa con la variable explicativa ``educ`` y puede ser utilizado de manera confiable en el modelo de variables instrumentales (IV) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F test de exclusión del instrumento:\n",
      "F-statistic = 12.86\n",
      "Prob > F = 0.0003\n"
     ]
    }
   ],
   "source": [
    "# Primera etapa: Regresión de 'educ' sobre 'nearc4' y controles\n",
    "y_first_stage = data['educ']\n",
    "X_first_stage = sm.add_constant(data[['nearc4', 'momdad14', 'south', 'black', 'smsa', \n",
    "                                      'reg661', 'reg662', 'reg663', 'reg664', 'reg665', \n",
    "                                      'reg666', 'reg667', 'reg668', 'smsa66']])\n",
    "\n",
    "model_first_stage = sm.OLS(y_first_stage, X_first_stage).fit()\n",
    "\n",
    "# Evaluación de la fuerza del instrumento (F-statistic)\n",
    "coef_nearc4 = model_first_stage.params['nearc4']\n",
    "cov_nearc4 = model_first_stage.cov_params().loc['nearc4', 'nearc4']\n",
    "f_stat = (coef_nearc4 ** 2) / cov_nearc4\n",
    "df_num = 1  # Numerador: 1 grado de libertad por instrumento\n",
    "df_den = model_first_stage.df_resid  # Denominador: grados de libertad residuales\n",
    "p_value = 1 - stats.f.cdf(f_stat, df_num, df_den)\n",
    "\n",
    "print(f\"\\nF test de exclusión del instrumento:\\nF-statistic = {f_stat:.2f}\\nProb > F = {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii) el estadístico de Cragg y Donald (1993)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que el valor p es 0.0000, podemos rechazar la hipótesis nula de que los instrumentos son débiles. Esto significa que los instrumentos que estás utilizando son fuertes y no presentan problemas de identificación débil en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estadístico de Cragg y Donald (1993): 18596.42\n",
      "P-value para el estadístico de Cragg y Donald: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Primera etapa: Regresión de 'educ' sobre 'nearc4' y controles\n",
    "y_first_stage = data['educ']\n",
    "X_first_stage = sm.add_constant(data[['nearc4', 'momdad14', 'south', 'black', 'smsa', \n",
    "                                      'reg661', 'reg662', 'reg663', 'reg664', 'reg665', \n",
    "                                      'reg666', 'reg667', 'reg668', 'smsa66']])\n",
    "\n",
    "# Regresión OLS de la primera etapa\n",
    "model_first_stage = sm.OLS(y_first_stage, X_first_stage).fit()\n",
    "\n",
    "# Obtener los residuos de la primera etapa\n",
    "residuals_first_stage = model_first_stage.resid\n",
    "\n",
    "# Estimación de la matriz de varianzas-covarianzas de los instrumentos\n",
    "instrument_matrix = sm.add_constant(data[['nearc4', 'momdad14', 'south', 'black', 'smsa', \n",
    "                                          'reg661', 'reg662', 'reg663', 'reg664', 'reg665', \n",
    "                                          'reg666', 'reg667', 'reg668', 'smsa66']])\n",
    "cov_matrix = np.linalg.inv(instrument_matrix.T @ instrument_matrix)\n",
    "\n",
    "# Estadístico de Cragg y Donald\n",
    "n = len(data)  # Número de observaciones\n",
    "k = len(instrument_matrix.columns)  # Número de instrumentos\n",
    "residual_sum_of_squares = residuals_first_stage.T @ residuals_first_stage  # Suma de cuadrados de los residuos\n",
    "\n",
    "# Estadístico de Cragg y Donald (1993)\n",
    "cragg_donald_statistic = (residual_sum_of_squares / n) * (n - k)  # Estadístico de Cragg y Donald\n",
    "\n",
    "# Valor crítico (aproximado) para la distribución chi-cuadrada\n",
    "dof = k - 1  # Grados de libertad (número de instrumentos - 1)\n",
    "p_value_cragg_donald = 1 - stats.chi2.cdf(cragg_donald_statistic, df=dof)\n",
    "\n",
    "print(f\"\\nEstadístico de Cragg y Donald (1993): {cragg_donald_statistic:.2f}\")\n",
    "print(f\"P-value para el estadístico de Cragg y Donald: {p_value_cragg_donald:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### iii) las tablas de Stock y Yogo (2005) con respecto a la medida del test de Wald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'get_loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12408\\1038805212.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Para probar si el coeficiente de 'nearc4' es cero en el modelo IV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Usamos get_loc para obtener la posición de 'nearc4' en el índice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mr_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miv_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mr_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miv_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nearc4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m  \u001b[1;31m# Esto especifica que probamos el coeficiente de 'nearc4'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Prueba de Wald utilizando el método directamente del modelo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mwald_stat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miv_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwald_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         ):\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'get_loc'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
    "\n",
    "# Ajustar el modelo IV\n",
    "iv_model = IV2SLS(y_second_stage, sm.add_constant(X_second_stage), sm.add_constant(Z)).fit()\n",
    "\n",
    "# Supongamos que quieres probar si el coeficiente de 'nearc4' es cero\n",
    "# r_matrix es una matriz que tiene una fila por cada restricción y una columna por cada parámetro del modelo\n",
    "# Para probar si el coeficiente de 'nearc4' es cero en el modelo IV\n",
    "\n",
    "# Usamos get_loc para obtener la posición de 'nearc4' en el índice\n",
    "r_matrix = np.zeros((1, len(iv_model.params)))\n",
    "r_matrix[0, iv_model.params.get_loc('nearc4')] = 1  # Esto especifica que probamos el coeficiente de 'nearc4'\n",
    "\n",
    "# Prueba de Wald utilizando el método directamente del modelo\n",
    "wald_stat = iv_model.wald_test(r_matrix)\n",
    "\n",
    "# Valor de la estadística y p-valor\n",
    "wald_value = wald_stat.statistic[0]\n",
    "wald_pvalue = wald_stat.pvalue\n",
    "\n",
    "print(f\"\\nEstadístico de Wald: {wald_value:.2f}\")\n",
    "print(f\"P-value de la prueba de Wald: {wald_pvalue:.4f}\")\n",
    "\n",
    "# Valores críticos de Stock y Yogo (2005) para 1 instrumento endógeno\n",
    "print(\"\\nValores críticos de Stock y Yogo (2005):\")\n",
    "print(\"Para el nivel de significancia de 10%: Valor crítico = 16.38\")\n",
    "print(\"Para el nivel de significancia de 15%: Valor crítico = 8.96\")\n",
    "print(\"Para el nivel de significancia de 20%: Valor crítico = 6.66\")\n",
    "print(\"Para el nivel de significancia de 25%: Valor crítico = 5.53\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYK2U54ENGgF"
   },
   "source": [
    "### 7. **Use `nearc2` con `nearc4` como instrumentos para educ. <br> Primero estime la primera etapa para `educ` y analice cuál de los dos instrumentos está más fuertemente relacionada parcialmente con `educ`. <br> Después use el estimador de IV usando por separado `nearc2` y `nearc4` como instrumento para educ. <br> Luego use el de 2SLS (incluyendo ambos instrumentos). <br> Discuta sus resultados. Verifique que el estimador 2SLS es válido.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "plj79gs1NKg1",
    "outputId": "7465f01d-3e09-435a-ab71-2596de8fc051"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<class 'statsmodels.iolib.summary.Summary'>\n",
       " \"\"\"\n",
       "                             OLS Regression Results                            \n",
       " ==============================================================================\n",
       " Dep. Variable:                   educ   R-squared:                       0.002\n",
       " Model:                            OLS   Adj. R-squared:                  0.002\n",
       " Method:                 Least Squares   F-statistic:                     6.759\n",
       " Date:                Sun, 08 Dec 2024   Prob (F-statistic):            0.00937\n",
       " Time:                        19:20:09   Log-Likelihood:                -7231.0\n",
       " No. Observations:                3010   AIC:                         1.447e+04\n",
       " Df Residuals:                    3008   BIC:                         1.448e+04\n",
       " Df Model:                           1                                         \n",
       " Covariance Type:            nonrobust                                         \n",
       " ==============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       " ------------------------------------------------------------------------------\n",
       " Intercept     13.1509      0.065    201.734      0.000      13.023      13.279\n",
       " nearc2         0.2553      0.098      2.600      0.009       0.063       0.448\n",
       " ==============================================================================\n",
       " Omnibus:                       35.903   Durbin-Watson:                   1.597\n",
       " Prob(Omnibus):                  0.000   Jarque-Bera (JB):               38.498\n",
       " Skew:                          -0.236   Prob(JB):                     4.37e-09\n",
       " Kurtosis:                       3.289   Cond. No.                         2.50\n",
       " ==============================================================================\n",
       " \n",
       " Notes:\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       " \"\"\",\n",
       " <class 'statsmodels.iolib.summary.Summary'>\n",
       " \"\"\"\n",
       "                             OLS Regression Results                            \n",
       " ==============================================================================\n",
       " Dep. Variable:                   educ   R-squared:                       0.021\n",
       " Model:                            OLS   Adj. R-squared:                  0.020\n",
       " Method:                 Least Squares   F-statistic:                     63.91\n",
       " Date:                Sun, 08 Dec 2024   Prob (F-statistic):           1.84e-15\n",
       " Time:                        19:20:09   Log-Likelihood:                -7202.7\n",
       " No. Observations:                3010   AIC:                         1.441e+04\n",
       " Df Residuals:                    3008   BIC:                         1.442e+04\n",
       " Df Model:                           1                                         \n",
       " Covariance Type:            nonrobust                                         \n",
       " ==============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       " ------------------------------------------------------------------------------\n",
       " Intercept     12.6980      0.086    148.269      0.000      12.530      12.866\n",
       " nearc4         0.8290      0.104      7.994      0.000       0.626       1.032\n",
       " ==============================================================================\n",
       " Omnibus:                       26.936   Durbin-Watson:                   1.626\n",
       " Prob(Omnibus):                  0.000   Jarque-Bera (JB):               28.373\n",
       " Skew:                          -0.204   Prob(JB):                     6.90e-07\n",
       " Kurtosis:                       3.243   Cond. No.                         3.31\n",
       " ==============================================================================\n",
       " \n",
       " Notes:\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       " \"\"\")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primera etapa: Regresión de educ sobre los instrumentos (nearc2 y nearc4) y covariables relevantes\n",
    "# Incluimos un intercepto automáticamente con statsmodels\n",
    "model_educ_nearc2 = smf.ols('educ ~ nearc2', data=data).fit()\n",
    "model_educ_nearc4 = smf.ols('educ ~ nearc4', data=data).fit()\n",
    "\n",
    "# Resumen de las regresiones\n",
    "summary_nearc2 = model_educ_nearc2.summary()\n",
    "summary_nearc4 = model_educ_nearc4.summary()\n",
    "\n",
    "summary_nearc2, summary_nearc4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNmlOGO_KsI7"
   },
   "source": [
    "En la primera etapa, ambos instrumentos (nearc2 y nearc4) muestran estar relacionados parcialmente con la educación (educ), pero con diferente intensidad. Para nearc2, el coeficiente estimado es 0.2553, lo que indica que vivir cerca de una universidad (según este indicador) incrementa los años de educación en promedio en 0.2553 años. Esta relación es estadísticamente significativa (𝑝 = 0.009), aunque la proporción de varianza explicada ($R^2$= 0.002) es baja, sugiriendo que su capacidad explicativa es limitada. Por otro lado, el coeficiente de nearc4 es 0.8290, mucho mayor que el de nearc2, indicando un efecto más fuerte sobre la educación. Además, este resultado es altamente significativo (𝑝 < 0.001) y presenta un $R^2$ = 0.021, lo que muestra una mayor capacidad explicativa que nearc2. Por lo tanto, nearc4 está más fuertemente relacionado con educ, y se perfila como un instrumento más robusto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64jB708oC9jX",
    "outputId": "7801daab-5ca8-41e3-b047-02e00dbbb976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IV usando nearc2 como instrumento:\n",
      "                          IV2SLS Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   wage   R-squared:                      -4.494\n",
      "Model:                         IV2SLS   Adj. R-squared:                 -4.496\n",
      "Method:                     Two Stage   F-statistic:                     7.328\n",
      "                        Least Squares   Prob (F-statistic):            0.00683\n",
      "Date:                Sun, 08 Dec 2024                                         \n",
      "Time:                        19:20:13                                         \n",
      "No. Observations:                3010                                         \n",
      "Df Residuals:                    3008                                         \n",
      "Df Model:                           1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -2606.0492   1176.037     -2.216      0.027   -4911.967    -300.132\n",
      "educ         240.0077     88.663      2.707      0.007      66.161     413.855\n",
      "==============================================================================\n",
      "Omnibus:                       13.883   Durbin-Watson:                   1.736\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               14.095\n",
      "Skew:                           0.150   Prob(JB):                     0.000869\n",
      "Kurtosis:                       3.150   Cond. No.                         68.8\n",
      "==============================================================================\n",
      "\n",
      "IV usando nearc4 como instrumento:\n",
      "                          IV2SLS Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   wage   R-squared:                      -0.538\n",
      "Model:                         IV2SLS   Adj. R-squared:                 -0.539\n",
      "Method:                     Two Stage   F-statistic:                     48.80\n",
      "                        Least Squares   Prob (F-statistic):           3.48e-12\n",
      "Date:                Sun, 08 Dec 2024                                         \n",
      "Time:                        19:20:13                                         \n",
      "No. Observations:                3010                                         \n",
      "Df Residuals:                    3008                                         \n",
      "Df Model:                           1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       -849.4984    204.338     -4.157      0.000   -1250.154    -448.843\n",
      "educ         107.5723     15.400      6.985      0.000      77.378     137.767\n",
      "==============================================================================\n",
      "Omnibus:                      102.737   Durbin-Watson:                   1.836\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              139.507\n",
      "Skew:                           0.360   Prob(JB):                     5.09e-31\n",
      "Kurtosis:                       3.771   Cond. No.                         68.8\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Variables dependientes y explicativas\n",
    "y = data['wage']  # Variable dependiente\n",
    "X = data[['educ']]  # Variable explicativa\n",
    "\n",
    "# IV con nearc2\n",
    "Z_nearc2 = data[['nearc2']]  # Instrumento\n",
    "iv_nearc2 = IV2SLS(y, sm.add_constant(X), sm.add_constant(Z_nearc2)).fit()\n",
    "\n",
    "# IV con nearc4\n",
    "Z_nearc4 = data[['nearc4']]  # Instrumento\n",
    "iv_nearc4 = IV2SLS(y, sm.add_constant(X), sm.add_constant(Z_nearc4)).fit()\n",
    "\n",
    "print(\"IV usando nearc2 como instrumento:\")\n",
    "print(iv_nearc2.summary())\n",
    "print(\"\\nIV usando nearc4 como instrumento:\")\n",
    "print(iv_nearc4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31qumvlHNSIW"
   },
   "source": [
    "\n",
    "En la estimación usando nearc2 como instrumento, el coeficiente de educ fue de 240.01, indicando que un año adicional de educación incrementa el salario promedio en 240 unidades monetarias. Este coeficiente es estadísticamente significativo (𝑝 = 0.007). Sin embargo, el $R^2$ = −4.494 sugiere que el modelo tiene problemas para explicar la variación en los salarios, lo que puede reflejar una debilidad del instrumento o un ajuste limitado del modelo. Por otro lado, al usar nearc4 como instrumento, el coeficiente de educ fue de 107.57, también positivo y significativo (𝑝 < 0.001), pero con un menor impacto relativo en comparación con nearc2. Además, el $R^2$ = −0.538 indica un ajuste del modelo algo mejor que el de nearc2, pero aún con problemas.\n",
    "\n",
    "Al comparar los resultados, nearc4 parece ser un instrumento más fuerte y consistente, ya que produce un coeficiente significativo y con menor error estándar. En ambos casos, los coeficientes de educ respaldan la hipótesis de que la educación tiene un impacto positivo en los salarios, pero la calidad del ajuste del modelo es limitada, probablemente por las características de los instrumentos o por factores no capturados en el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZBxF8gdrDche",
    "outputId": "aec3547d-c2ca-4745-ec2f-9bdeb522b834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2SLS usando ambos instrumentos:\n",
      "                          IV2SLS Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   wage   R-squared:                      -0.689\n",
      "Model:                         IV2SLS   Adj. R-squared:                 -0.689\n",
      "Method:                     Two Stage   F-statistic:                     54.35\n",
      "                        Least Squares   Prob (F-statistic):           2.16e-13\n",
      "Date:                Sun, 08 Dec 2024                                         \n",
      "Time:                        19:20:16                                         \n",
      "No. Observations:                3010                                         \n",
      "Df Residuals:                    3008                                         \n",
      "Df Model:                           1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       -966.6389    209.521     -4.614      0.000   -1377.459    -555.819\n",
      "educ         116.4042     15.790      7.372      0.000      85.444     147.364\n",
      "==============================================================================\n",
      "Omnibus:                       71.486   Durbin-Watson:                   1.831\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               89.396\n",
      "Skew:                           0.302   Prob(JB):                     3.87e-20\n",
      "Kurtosis:                       3.590   Cond. No.                         68.8\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# 2SLS con nearc2 y nearc4\n",
    "Z_both = data[['nearc2', 'nearc4']]  # Ambos instrumentos\n",
    "iv_both = IV2SLS(y, sm.add_constant(X), sm.add_constant(Z_both)).fit()\n",
    "\n",
    "print(\"2SLS usando ambos instrumentos:\")\n",
    "print(iv_both.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tex8Iz1GOtbe"
   },
   "source": [
    "Al usar ambos instrumentos (nearc2 y nearc4) en un modelo 2SLS, el coeficiente de educ es 116.40, indicando que un año adicional de educación incrementa los salarios promedio en 116.4 unidades monetarias. Este coeficiente es altamente significativo (𝑝 < 0.001), lo que refuerza la relación positiva entre educación y salario. La fortaleza conjunta de los instrumentos está respaldada por un 𝐹-statistic de 54.35 (𝑝 < 0.001), lo que sugiere que el modelo cumple con la condición de relevancia instrumental. Sin embargo, el $R^2$ = − 0.689 indica que el modelo aún tiene dificultades para capturar la variación en los salarios, posiblemente debido a factores no modelados o limitaciones en la especificación. Este resultado muestra que combinar ambos instrumentos mejora la precisión de las estimaciones frente a usarlos de forma individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00mgKp-0Df1d",
    "outputId": "bb7e6090-eb88-4023-ced8-a7cdf6c4b7ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lagrange multiplier statistic': 9.442191564833468, 'p-value': 0.023954364427434042, 'f-value': 3.1531057063344305, 'f p-value': 0.023912439438320814}\n"
     ]
    }
   ],
   "source": [
    "# Verificación de instrumentos\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "\n",
    "# Residuales del modelo\n",
    "resid_2sls = iv_both.resid\n",
    "# Prueba de Breusch-Pagan para heterocedasticidad\n",
    "bp_test = het_breuschpagan(resid_2sls, sm.add_constant(data[['educ', 'nearc2', 'nearc4']]))\n",
    "labels = ['Lagrange multiplier statistic', 'p-value', 'f-value', 'f p-value']\n",
    "print(dict(zip(labels, bp_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEIZnULeP-jW"
   },
   "source": [
    "Para evaluar la validez del estimador 2SLS, el resultado del test de sobreidentificación (Lagrange Multiplier Statistic o Sargan Test) tiene un valor estadístico de 9.44 y un 𝑝-valor de 0.0239, lo que indica que rechazamos la hipótesis nula de que los instrumentos son válidos al nivel de significancia del 5%. Esto sugiere que al menos uno de los instrumentos (nearc2 o nearc4) podría no ser válido, lo cual afecta la consistencia del estimador 2SLS. Además, el valor de 𝑓-statistic en la primera etapa es 3.15, con un 𝑝-valor de 0.0239, lo que señala que los instrumentos tienen relevancia débil en la predicción de educ. En conjunto, aunque los coeficientes obtenidos en el modelo 2SLS con ambos instrumentos son significativos y consistentes con las estimaciones individuales, estos resultados ponen en duda la fiabilidad de las estimaciones obtenidas con 2SLS. Esto sugiere la necesidad de reevaluar los instrumentos o considerar métodos más robustos para validar los resultados y garantizar conclusiones consistentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvQHXkI9NK6J"
   },
   "source": [
    "### 8. **Hemos asumido hasta ahora homoscedasticidad ¿Es razonable esto?¿Qué permite el estimador de GMM que no permite el de IV en 2 etapas bajo heterosk. Compare los resultados (del coeficiente educación) del estimador 2SLS con el del estimador GMM bajo heterocedasticidad**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YjPaiQt3Ngl4",
    "outputId": "8538c4ed-dcf7-438d-944c-3c61ec21a69e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 273.616758\n",
      "         Iterations: 14\n",
      "         Function evaluations: 18\n",
      "         Gradient evaluations: 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002301\n",
      "         Iterations: 3\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002302\n",
      "         Iterations: 0\n",
      "         Function evaluations: 1\n",
      "         Gradient evaluations: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002302\n",
      "         Iterations: 0\n",
      "         Function evaluations: 1\n",
      "         Gradient evaluations: 1\n",
      "GMM bajo heterocedasticidad:\n",
      "                                IVGMM Results                                 \n",
      "==============================================================================\n",
      "Dep. Variable:                   wage   Hansen J:                        6.930\n",
      "Model:                          IVGMM   Prob (Hansen J):               0.00848\n",
      "Method:                           GMM                                         \n",
      "Date:                Sun, 08 Dec 2024                                         \n",
      "Time:                        19:20:29                                         \n",
      "No. Observations:                3010                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       -966.6439    204.548     -4.726      0.000   -1367.551    -565.737\n",
      "educ         116.3389     15.446      7.532      0.000      86.066     146.612\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Estimador GMM con ambos instrumentos\n",
    "gmm_model = IVGMM(y, sm.add_constant(X), sm.add_constant(Z_both))\n",
    "gmm_result = gmm_model.fit()\n",
    "print(\"GMM bajo heterocedasticidad:\")\n",
    "print(gmm_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "slggmGqkD2qd",
    "outputId": "ed0dafad-e288-4ab2-c118-771e5b183e88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficiente 2SLS (educ): 116.40415798679044\n",
      "Coeficiente GMM (educ): 116.33894403448211\n"
     ]
    }
   ],
   "source": [
    "print(\"Coeficiente 2SLS (educ):\", iv_both.params['educ'])\n",
    "print(\"Coeficiente GMM (educ):\", gmm_result.params[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9hnEjArRfp9"
   },
   "source": [
    "El supuesto de homoscedasticidad puede no ser razonable en este caso, ya que las condiciones reales de los datos a menudo presentan heterocedasticidad, lo que podría afectar la consistencia de los estimadores clásicos como el 2SLS. El estimador GMM, a diferencia del 2SLS, es robusto frente a heterocedasticidad, ya que utiliza matrices de varianzas y covarianzas que no dependen de este supuesto. Al comparar los resultados, el coeficiente de educación bajo 2SLS es de 116.404, mientras que bajo GMM es de 116.339; ambos son muy similares, lo que sugiere que la heterocedasticidad no tiene un impacto significativo en la estimación del coeficiente en este caso. Sin embargo, el Hansen J-test del modelo GMM (valor: 6.93, p-valor: 0.0085) cuestiona la validez de los instrumentos, indicando que podrían no ser completamente exógenos, lo cual requiere un análisis más profundo para confirmar la robustez de los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3BIl515pn1Eu"
   },
   "source": [
    "### 9. Sigamos con el caso donde se tienen dos instrumentos. Dado lo hallado en términos de si los instrumentos por separado son débiles o no en la pregunta 7, ¿qué concluye ud. a partir del resultado del test de sobreidentificación? <br> ¿Con qué instrumento o instrumentos se quedaría al final? Realícelo asumiendo heterocedascidad para el estimador GMM y 2SLS <br> *(HINT: piense 2 veces)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-kj3zGCdoi0o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUkn7SV8n1jT"
   },
   "source": [
    "### 10. ¿Deberíamos usar MCO y aceptar la inconsistencia o usar en vez IV a pesar de que es un estimador consistente pero ineficiente? <br> ¿Hay forma de testear esto? <br> Si sí, llévela a cabo para el modelo sobre-identificado. ¿Qué concluye?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "POaBvbJ2okr6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "bjKfEzD3kKGI",
    "YmDUmxlzkPxj",
    "Fnmi4tkzlzDD",
    "8zd0KB_0mlWL",
    "X-5_L_vZnAVD",
    "9k2iQwX7nN3B"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
